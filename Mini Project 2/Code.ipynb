{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b263fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import invwishart, invgamma\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import gamma \n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41ea00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "249225d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "def generate_samples(n):\n",
    "    # size = nx2\n",
    "    mean = np.array([0,0])\n",
    "    cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "    samples = np.random.multivariate_normal(mean,cov,size=n)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba6412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n10 = generate_samples(10)\n",
    "n100 = generate_samples(100)\n",
    "n1000 = generate_samples(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "590fb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(samples, estimate):\n",
    "    return np.linalg.norm(samples - estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b191fe",
   "metadata": {},
   "source": [
    "## Ques - 1 : MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc131dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_estimate(samples):\n",
    "    return samples.T@samples/len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a23bf0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [0.95639504 0.5114831 ] \n",
      " \t\t[0.5114831  1.70687007] \t Error : 0.78170100869855 \n",
      "\n",
      "N100 estimate : [1.09090575 0.06765193] \n",
      " \t\t[0.06765193 1.42585811] \t Error : 0.5891148760120036 \n",
      "\n",
      "N1000 estimate : [ 1.00312518 -0.00914911] \n",
      " \t\t[-0.00914911  1.92430787] \t Error : 0.07685361366732414 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mle_n10 = mle_estimate(n10)\n",
    "mle_n100 = mle_estimate(n100)\n",
    "mle_n1000 = mle_estimate(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mle_n10[0]} \\n \\t\\t{mle_n10[1]} \\t\", f\"Error : {get_error(true_cov, mle_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mle_n100[0]} \\n \\t\\t{mle_n100[1]} \\t\", f\"Error : {get_error(true_cov, mle_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mle_n1000[0]} \\n \\t\\t{mle_n1000[1]} \\t\", f\"Error : {get_error(true_cov, mle_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac089be",
   "metadata": {},
   "source": [
    "### Ques - 2 : Bayesian Est with Conjugate Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e326e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_invwishart_cp(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    d = 1\n",
    "    dof = n + v0\n",
    "    scale = delta0 + samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0b7c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.0433808  0.39344854] \n",
      " \t\t[0.39344854 1.69759236] \t Error : 0.6347722240374717 \n",
      "\n",
      "N100 estimate : [1.09796675 0.06568148] \n",
      " \t\t[0.06568148 1.43287195] \t Error : 0.5829749793964033 \n",
      "\n",
      "N1000 estimate : [ 1.00411284 -0.00912175] \n",
      " \t\t[-0.00912175  1.92353726] \t Error : 0.07765229561546912 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bayes_invwis_n10 = bayesian_estimate_invwishart_cp(n10)\n",
    "bayes_invwis_n100 = bayesian_estimate_invwishart_cp(n100)\n",
    "bayes_invwis_n1000 = bayesian_estimate_invwishart_cp(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {bayes_invwis_n10[0]} \\n \\t\\t{bayes_invwis_n10[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {bayes_invwis_n100[0]} \\n \\t\\t{bayes_invwis_n100[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {bayes_invwis_n1000[0]} \\n \\t\\t{bayes_invwis_n1000[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a3171",
   "metadata": {},
   "source": [
    "### Ques - 3 : Bayesian Est with Non-informative Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f54ebc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_jeffery(samples):\n",
    "    # https://tminka.github.io/papers/minka-gaussian.pdf\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)\n",
    "\n",
    "def bayesian_estimate_ind_jeffery(samples):\n",
    "    # gelman page 72\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n - 1\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f205d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.1954938  0.63935387] \n",
      " \t\t[0.63935387 2.13358758] \t Error : 0.9346711809305068 \n",
      "\n",
      "N100 estimate : [1.11316913 0.06903258] \n",
      " \t\t[0.06903258 1.45495725] \t Error : 0.5651635564589236 \n",
      "\n",
      "N1000 estimate : [ 1.00513545 -0.00916745] \n",
      " \t\t[-0.00916745  1.9281642 ] \t Error : 0.07317676920946582 \n",
      "\n",
      "\n",
      "\n",
      "N10 estimate : [1.36627863 0.73069014] \n",
      " \t\t[0.73069014 2.43838581] \t Error : 1.180744813626069 \n",
      "\n",
      "N100 estimate : [1.1246451  0.06974426] \n",
      " \t\t[0.06974426 1.46995681] \t Error : 0.5533630885390415 \n",
      "\n",
      "N1000 estimate : [ 1.00614361 -0.00917664] \n",
      " \t\t[-0.00917664  1.93009816] \t Error : 0.07136127951600006 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jeffery_n10 = bayesian_estimate_jeffery(n10)\n",
    "jeffery_n100 = bayesian_estimate_jeffery(n100)\n",
    "jeffery_n1000 = bayesian_estimate_jeffery(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {jeffery_n10[0]} \\n \\t\\t{jeffery_n10[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {jeffery_n100[0]} \\n \\t\\t{jeffery_n100[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {jeffery_n1000[0]} \\n \\t\\t{jeffery_n1000[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n1000)}\" , \"\\n\") \n",
    "print(\"\\n\")\n",
    "\n",
    "jeffery_ind_n10 = bayesian_estimate_ind_jeffery(n10)\n",
    "jeffery_ind_n100 = bayesian_estimate_ind_jeffery(n100)\n",
    "jeffery_ind_n1000 = bayesian_estimate_ind_jeffery(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {jeffery_ind_n10[0]} \\n \\t\\t{jeffery_ind_n10[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {jeffery_ind_n100[0]} \\n \\t\\t{jeffery_ind_n100[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {jeffery_ind_n1000[0]} \\n \\t\\t{jeffery_ind_n1000[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacb7f7",
   "metadata": {},
   "source": [
    "### Ques 4 : MC Bayesian Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "501e4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_bayesian_a(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    vals = []\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "\n",
    "\n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            det_term = np.clip(det_term, 1e-100, 1e100)\n",
    "\n",
    "            exp_term = np.exp(np.clip(-0.5*np.trace(np.linalg.inv(sigma_j)@(samples.T@samples)), 1e-100, 1e100))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\")\n",
    "        vals.append(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    return np.array(vals)\n",
    "\n",
    "def mc_bayesian_b(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[2,0],[0,4]])\n",
    "    vals = []\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            \n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            det_term = np.clip(det_term, 1e-100, 1e100)\n",
    "\n",
    "            exp_term = np.exp(np.clip(-0.5*np.trace(np.linalg.inv(sigma_j)@(samples.T@samples)), 1e-100, 1e100))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        # print(f\"For m={m}:\")\n",
    "        vals.append(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        # print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        # print(\"\\n\")\n",
    "    \n",
    "    return np.array(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "821976f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=1000.0:\n",
      "[[ 0.42129131 -0.05570106]\n",
      " [-0.05570106  0.55658186]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[0.35406946 0.02864073]\n",
      " [0.02864073 0.42277761]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[ 0.35523343 -0.01397862]\n",
      " [-0.01397862  0.43682538]]\n",
      "\n",
      "\n",
      "For m=1000.0:\n",
      "[[ 0.45756342 -0.05679105]\n",
      " [-0.05679105  0.29806271]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[ 0.28990321 -0.03090174]\n",
      " [-0.03090174  0.3200495 ]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[0.29938395 0.03149522]\n",
      " [0.03149522 0.19033859]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\514092026.py:14: RuntimeWarning: overflow encountered in scalar power\n",
      "  det_term = np.linalg.det(sigma_j)**(-n/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=1000.0:\n",
      "[[ 0.67337575 -0.02885583]\n",
      " [-0.02885583  0.8390366 ]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[ 0.66554155 -0.00359107]\n",
      " [-0.00359107  0.80894623]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[0.65994007 0.00188641]\n",
      " [0.00188641 0.82422498]]\n",
      "\n",
      "\n",
      "N10 estimate : [[ 0.42129131 -0.05570106]\n",
      " [-0.05570106  0.55658186]] \n",
      " \t\t[[0.35406946 0.02864073]\n",
      " [0.02864073 0.42277761]] \t Error : [1.5571014364427667, 1.704845249146786, 1.6910439498727463] \n",
      "\n",
      "N100 estimate : [[ 0.45756342 -0.05679105]\n",
      " [-0.05679105  0.29806271]] \n",
      " \t\t[[ 0.28990321 -0.03090174]\n",
      " [-0.03090174  0.3200495 ]] \t Error : [1.7880935231813204, 1.8243850956385712, 1.9410618648454727] \n",
      "\n",
      "N1000 estimate : [[ 0.67337575 -0.02885583]\n",
      " [-0.02885583  0.8390366 ]] \n",
      " \t\t[[ 0.66554155 -0.00359107]\n",
      " [-0.00359107  0.80894623]] \t Error : [1.2067247976470958, 1.2371327029785302, 1.2239668159318635] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\514092026.py:40: RuntimeWarning: overflow encountered in scalar power\n",
      "  det_term = np.linalg.det(sigma_j)**(-n/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [[0.16371264 0.01864841]\n",
      " [0.01864841 0.31191436]] \n",
      " \t\t[[0.13352261 0.00280176]\n",
      " [0.00280176 0.31742649]] \t Error : [1.8840661373271026, 1.892578233570864, 1.8687357966899243] \n",
      "\n",
      "N100 estimate : [[0.14848515 0.02668915]\n",
      " [0.02668915 0.26057462]] \n",
      " \t\t[[ 0.16338485 -0.03012443]\n",
      " [-0.03012443  0.20083881]] \t Error : [1.9370345433066758, 1.9846210844515197, 2.004904615297301] \n",
      "\n",
      "N1000 estimate : [[0.46068712 0.01947195]\n",
      " [0.01947195 0.9643173 ]] \n",
      " \t\t[[0.4830285  0.00424663]\n",
      " [0.00424663 0.94960993]] \t Error : [1.1680134248446845, 1.1707326338567143, 1.171248389323076] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_a_n10 = mc_bayesian_a(n10)\n",
    "mc_a_n100 = mc_bayesian_a(n100)\n",
    "mc_a_n1000 = mc_bayesian_a(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mc_a_n10[0]} \\n \\t\\t{mc_a_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n10] }\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mc_a_n100[0]} \\n \\t\\t{mc_a_n100[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n100]}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mc_a_n1000[0]} \\n \\t\\t{mc_a_n1000[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n1000]}\" , \"\\n\") \n",
    "print(\"\\n\")\n",
    "\n",
    "mc_b_n10 =  mc_bayesian_b(n10)\n",
    "mc_b_n100 =  mc_bayesian_b(n100)\n",
    "mc_b_n1000 =  mc_bayesian_b(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mc_b_n10[0]} \\n \\t\\t{mc_b_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n10]}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mc_b_n100[0]} \\n \\t\\t{mc_b_n100[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n100]}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mc_b_n1000[0]} \\n \\t\\t{mc_b_n1000[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n1000]}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901bb1c",
   "metadata": {},
   "source": [
    "### Ques - 5 : Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd9b8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler(samples):\n",
    "    n = len(samples)\n",
    "    d = 2\n",
    "    v = 5 # to be checked\n",
    "    iter = 1e5\n",
    "    A_1 = 0.05\n",
    "    A_2 = 0.05\n",
    "\n",
    "    a1 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    a2 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    \n",
    "    sigmas = []\n",
    "    for i in tqdm(range(int(iter))):\n",
    "        if i%2 == 0:\n",
    "            sigma = invwishart.rvs(v+d+n-1, 2*v*np.array([[1/a1,0],[0,1/a2]])+samples.T@samples)\n",
    "            sigmas.append(sigma)\n",
    "        else:\n",
    "            a1 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[0][0])+1/(A_1**2))\n",
    "            a2 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[1][1])+1/(A_2**2))\n",
    "    \n",
    "    return np.array(sigmas[-1000:]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7026a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a44a19868d4138bc81a7d86aedfba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f62cce1497a47bcbe01dc71754e2df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64f6fdf2bef4c108161e6c961e1b44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [0.76632492 0.38759382] \n",
      " \t\t[0.38759382 1.29560019] \t Error : 0.9226272699390545 \n",
      "\n",
      "N100 estimate : [1.07416067 0.07000914] \n",
      " \t\t[0.07000914 1.39106728] \t Error : 0.6213705981750641 \n",
      "\n",
      "N1000 estimate : [ 1.01225181 -0.01014911] \n",
      " \t\t[-0.01014911  1.93534939] \t Error : 0.06734847862152363 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gibbs_n10 = gibbs_sampler(n10)\n",
    "gibbs_n100 = gibbs_sampler(n100)\n",
    "gibbs_n1000 = gibbs_sampler(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {gibbs_n10[0]} \\n \\t\\t{gibbs_n10[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {gibbs_n100[0]} \\n \\t\\t{gibbs_n100[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {gibbs_n1000[0]} \\n \\t\\t{gibbs_n1000[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n1000)}\" , \"\\n\") \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da30436",
   "metadata": {},
   "source": [
    "### Ques 6 : Empirical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97bf1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gammafn(x,d):\n",
    "    init = np.pi**(d*(d-1)/4)\n",
    "    for i in range(1,d+1):\n",
    "        init *= gamma(x + (1-i)/2)\n",
    "        init = np.clip(init, -1e30, 1e30)\n",
    "    return init\n",
    "\n",
    "def objective_function_voptimal(v,n,d):\n",
    "    v = np.clip(v, 1e-30, 1e30)\n",
    "    term_1 = v*np.log((v+n)/v)\n",
    "    term_2 = n*np.log((v+n)/n)\n",
    "    # print((v+n)/v , \"v\")\n",
    "    term_3 = np.log(np.clip(gammafn(v/2,d)/gammafn((v+n)/2,d), 1e-30, 1e30))\n",
    "    return term_1 + term_2 + term_3\n",
    "\n",
    "def EmpiricalBayes(samples,v0):\n",
    "    n,d = samples.shape\n",
    "    v_opt = minimize(lambda x: objective_function_voptimal(x,n,d), v0)\n",
    "    del_opt = v_opt.x[0]/n * samples.T@samples\n",
    "    #  InvWishart(νopt + n,∆opt + Σn) Calculate the posterior mean\n",
    "    posterior_mean = (del_opt + samples.T@samples ) / (v_opt.x[0] + n - d - 1)\n",
    "    return posterior_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a64349f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.04157568 0.55703797] \n",
      " \t\t[0.55703797 1.85889121] \t Error : 0.8013880606137168 \n",
      "\n",
      "N100 estimate : [1.1246625  0.06974534] \n",
      " \t\t[0.06974534 1.46997955] \t Error : 0.5533454958740844 \n",
      "\n",
      "N1000 estimate : [ 1.00614376 -0.00917664] \n",
      " \t\t[-0.00917664  1.93009845] \t Error : 0.07136100844284828 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"For n = 10 \\n{EmpiricalBayes(n10,5)}\")\n",
    "# print(f\"For n = 100 \\n{EmpiricalBayes(n100,5)}\")\n",
    "# print(f\"For n = 1000 \\n{EmpiricalBayes(n1000,5)}\")\n",
    "\n",
    "empirical_bayes_n10 = EmpiricalBayes(n10, 5)\n",
    "empirical_bayes_n100 = EmpiricalBayes(n100, 5)\n",
    "empirical_bayes_n1000 = EmpiricalBayes(n1000, 5)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {empirical_bayes_n10[0]} \\n \\t\\t{empirical_bayes_n10[1]} \\t\", f\"Error : {get_error(true_cov, empirical_bayes_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {empirical_bayes_n100[0]} \\n \\t\\t{empirical_bayes_n100[1]} \\t\", f\"Error : {get_error(true_cov, empirical_bayes_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {empirical_bayes_n1000[0]} \\n \\t\\t{empirical_bayes_n1000[1]} \\t\", f\"Error : {get_error(true_cov, empirical_bayes_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e2e4a",
   "metadata": {},
   "source": [
    "## Code without outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53299a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70647522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n):\n",
    "    # size = nx2\n",
    "    mean = np.array([0,0])\n",
    "    cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "    samples = np.random.multivariate_normal(mean,cov,size=n)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dae8cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n10 = generate_samples(10)\n",
    "n100 = generate_samples(100)\n",
    "n1000 = generate_samples(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbaaf67",
   "metadata": {},
   "source": [
    "### Ques - 1 : MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cceacf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_estimate(samples):\n",
    "    return samples.T@samples/len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed3658",
   "metadata": {},
   "source": [
    "### Ques - 2 : Bayesian Est with Conjugate Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ecde9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_invwishart_cp(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    d = 1\n",
    "    dof = n + v0\n",
    "    scale = delta0 + samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1f5088c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00411284, -0.00912175],\n",
       "       [-0.00912175,  1.92353726]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_estimate_invwishart_cp(n1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5e61a",
   "metadata": {},
   "source": [
    "### Ques - 3 : Bayesian Est with Non-informative Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71e92853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_jeffery(samples):\n",
    "    # https://tminka.github.io/papers/minka-gaussian.pdf\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)\n",
    "\n",
    "def bayesian_estimate_ind_jeffery(samples):\n",
    "    # gelman page 72\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n - 1\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d3087",
   "metadata": {},
   "source": [
    "### Ques 4 : MC Bayesian Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4f869ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_bayesian_a(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    cov_matrix = samples.T@samples\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            exp_term = np.exp(-0.5*np.trace(np.linalg.inv(sigma_j)@(cov_matrix)))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\\n\")\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "\n",
    "def mc_bayesian_b(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[2,0],[0,4]])\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            exp_term = np.exp(-0.5*np.trace(np.linalg.inv(sigma_j)@(samples.T@samples)))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\\n\")\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4ab94390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=1000.0:\n",
      "\n",
      "[[ 1.03729055 -0.03314606]\n",
      " [-0.03314606  2.06666036]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\2642150634.py:11: RuntimeWarning: overflow encountered in scalar power\n",
      "  det_term = np.linalg.det(sigma_j)**(-n/2)\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\2642150634.py:13: RuntimeWarning: invalid value encountered in multiply\n",
      "  numerators.append(sigma_j*det_term*exp_term)\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\2642150634.py:14: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  denominators.append(det_term*exp_term)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=10000.0:\n",
      "\n",
      "[[nan nan]\n",
      " [nan nan]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmc_bayesian_a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn1000\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[141], line 10\u001b[0m, in \u001b[0;36mmc_bayesian_a\u001b[1;34m(samples)\u001b[0m\n\u001b[0;32m      8\u001b[0m denominators \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(m)):\n\u001b[1;32m---> 10\u001b[0m     sigma_j \u001b[38;5;241m=\u001b[39m \u001b[43minvwishart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     det_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(sigma_j)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39mn\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m     exp_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mtrace(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(sigma_j)\u001b[38;5;241m@\u001b[39m(cov_matrix)))\n",
      "File \u001b[1;32mc:\\Users\\aksha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_multivariate.py:3023\u001b[0m, in \u001b[0;36minvwishart_gen.rvs\u001b[1;34m(self, df, scale, size, random_state)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[38;5;66;03m# Cholesky decomposition of scale\u001b[39;00m\n\u001b[0;32m   3021\u001b[0m C \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(scale, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 3023\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _squeeze_output(out)\n",
      "File \u001b[1;32mc:\\Users\\aksha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_multivariate.py:2978\u001b[0m, in \u001b[0;36minvwishart_gen._rvs\u001b[1;34m(self, n, shape, dim, df, C, random_state)\u001b[0m\n\u001b[0;32m   2976\u001b[0m random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_random_state(random_state)\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;66;03m# Get random draws A such that inv(A) ~ iW(df, I)\u001b[39;00m\n\u001b[1;32m-> 2978\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inv_standard_rvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2980\u001b[0m \u001b[38;5;66;03m# Calculate SA = (CA)'^{-1} (CA)^{-1} ~ iW(df, scale)\u001b[39;00m\n\u001b[0;32m   2981\u001b[0m trsm \u001b[38;5;241m=\u001b[39m get_blas_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrsm\u001b[39m\u001b[38;5;124m'\u001b[39m), (A,))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mc_bayesian_a(n1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "46b6c514",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.linalg' has no attribute 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmc_bayesian_a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn1000\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[118], line 12\u001b[0m, in \u001b[0;36mmc_bayesian_a\u001b[1;34m(samples)\u001b[0m\n\u001b[0;32m     10\u001b[0m sigma_j \u001b[38;5;241m=\u001b[39m invwishart\u001b[38;5;241m.\u001b[39mrvs(v0,delta0)\n\u001b[0;32m     11\u001b[0m det_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(sigma_j)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39mn\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m exp_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(sigma_j)\u001b[38;5;241m@\u001b[39m(samples\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@samples\u001b[39m)))\n\u001b[0;32m     13\u001b[0m numerators\u001b[38;5;241m.\u001b[39mappend(sigma_j\u001b[38;5;241m*\u001b[39mdet_term\u001b[38;5;241m*\u001b[39mexp_term)\n\u001b[0;32m     14\u001b[0m denominators\u001b[38;5;241m.\u001b[39mappend(det_term\u001b[38;5;241m*\u001b[39mexp_term)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.linalg' has no attribute 'trace'"
     ]
    }
   ],
   "source": [
    "mc_bayesian_a(n1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd4c50",
   "metadata": {},
   "source": [
    "### Ques - 5 : Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a77ed715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler(samples):\n",
    "    n = len(samples)\n",
    "    d = 2\n",
    "    v = 5 # to be checked\n",
    "    iter = 1e3\n",
    "    A_1 = 0.05\n",
    "    A_2 = 0.05\n",
    "\n",
    "    a1 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    a2 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    \n",
    "    sigmas = []\n",
    "    for i in range(int(iter)):\n",
    "        if i%2 == 0:\n",
    "            sigma = invwishart.rvs(v+d+n-1, 2*v*np.array([[1/a1,0],[0,1/a2]])+samples.T@samples)\n",
    "            sigmas.append(sigma)\n",
    "        else:\n",
    "            a1 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[0][0])+1/(A_1**2))\n",
    "            a2 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[1][1])+1/(A_2**2))\n",
    "    \n",
    "    return np.array(sigmas).mean(axis=0)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170bb91",
   "metadata": {},
   "source": [
    "### Ques 6 : Empirical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae920d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e124492",
   "metadata": {},
   "source": [
    "# Refoctoring Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cdcf33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import invwishart, invgamma\n",
    "from scipy.special import logsumexp\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import gamma \n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b32034",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bb7fa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "true_cov = np.array([[1,0],[0,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8832e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "79261655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gammafn(x,d):\n",
    "    init = np.pi**(d*(d-1)/4)\n",
    "    for i in range(1,d+1):\n",
    "        init *= gamma(x + (1-i)/2)\n",
    "        init = np.clip(init, -1e30, 1e30)\n",
    "    return init\n",
    "\n",
    "def objective_function_voptimal(v,n,d):\n",
    "    v = np.clip(v, 1e-30, 1e30)\n",
    "    term_1 = v*np.log((v+n)/v)\n",
    "    term_2 = n*np.log((v+n)/n)\n",
    "    # print((v+n)/v , \"v\")\n",
    "    term_3 = np.log(np.clip(gammafn(v/2,d)/gammafn((v+n)/2,d), 1e-30, 1e30))\n",
    "    return term_1 + term_2 + term_3\n",
    "\n",
    "def generate_samples(n):\n",
    "    # size = nx2\n",
    "    mean = np.array([0,0])\n",
    "    cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "    samples = np.random.multivariate_normal(mean,cov,size=n)\n",
    "    return samples\n",
    "\n",
    "def get_error(samples, estimate):\n",
    "    return np.linalg.norm(samples - estimate)\n",
    "\n",
    "n10 = generate_samples(10)\n",
    "n100 = generate_samples(100)\n",
    "n1000 = generate_samples(1000)\n",
    "errors = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce44167",
   "metadata": {},
   "source": [
    "## WorkHorses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8a448ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_estimate(samples:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Maximum Likelihood Estimate of covariance matrix\n",
    "    samples: nx2 matrix\n",
    "    returns: 2x2 covariance matrix\n",
    "    \"\"\"\n",
    "    return samples.T@samples/len(samples)\n",
    "\n",
    "def bayesian_estimate(samples :np.ndarray, delta0: np.ndarray, v0:int) -> np.ndarray:\n",
    "    \"\"\"Bayesian estimate of covariance matrix using Inverse Wishart prior\n",
    "    samples: nxd matrix\n",
    "    delta0: dxd matrix\n",
    "    v0: int\n",
    "    returns: dxd covariance matrix\n",
    "    \"\"\"\n",
    "    n,d = samples.shape\n",
    "    dof = n + v0\n",
    "    scale = delta0 + samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)\n",
    "\n",
    "def bayesian_estimate_using_MC(samples :np.ndarray, delta0: np.ndarray, v0:int) -> np.ndarray:\n",
    "    \"\"\"Bayesian estimate of covariance matrix using Inverse Wishart prior\n",
    "    samples: nxd matrix\n",
    "    delta0: dxd matrix\n",
    "    v0: int\n",
    "    returns: dxd covariance matrix\n",
    "    \"\"\"\n",
    "    n,d = samples.shape\n",
    "    cov_matrix = samples.T@samples\n",
    "    vals = []\n",
    "    for m in tqdm([1e3, 1e4, 1e5]):\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        sigmas = []\n",
    "        log_weights = []\n",
    "        for _ in tqdm(range(int(m))):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            det_term = (-n/2)*np.log(np.linalg.det(sigma_j))\n",
    "            exp_term = -0.5*np.trace(np.linalg.inv(sigma_j)@(samples.T@samples))\n",
    "            # numerators.append(sigma_j*det_term*exp_term)\n",
    "            # denominators.append(det_term*exp_term)\n",
    "            sigmas.append(sigma_j)\n",
    "            log_weights.append(det_term+exp_term)\n",
    "        log_denominator = logsumexp(log_weights)\n",
    "        ans = np.zeros((2,2))\n",
    "        for w,s in zip(log_weights, sigmas):\n",
    "            ans += np.exp(w-log_denominator)*s\n",
    "        # vals.append(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        vals.append(ans)\n",
    "    return np.array(vals)\n",
    "\n",
    "def gibbs_sampler(samples :np.ndarray, sigma: np.ndarray, v0:int) -> np.ndarray:\n",
    "    \"\"\"Gibbs sampler for covariance matrix for solving hierarchical bayes model\n",
    "    samples: nxd matrix\n",
    "    sigma: dxd matrix as an initial guess\n",
    "    v0: int\n",
    "    returns: dxd covariance matrix\n",
    "    \"\"\"\n",
    "    n,d = samples.shape\n",
    "    iter = 1e3\n",
    "    A_1 = 0.05\n",
    "    A_2 = 0.05\n",
    "    cov_matrix = samples.T@samples\n",
    "    \n",
    "    sigmas = []\n",
    "    for i in tqdm(range(int(iter))):\n",
    "        a1 = invgamma.rvs((v0+n)/2,scale=v0*(np.linalg.inv(sigma)[0][0])+1/(A_1**2))\n",
    "        a2 = invgamma.rvs((v0+n)/2,scale=v0*(np.linalg.inv(sigma)[1][1])+1/(A_2**2))\n",
    "        sigma = invwishart.rvs(v0+d+n-1, 2*v0*np.array([[1/a1,0],[0,1/a2]])+cov_matrix)\n",
    "        sigmas.append(sigma)\n",
    "    \n",
    "    return np.array(sigmas).mean(axis=0)\n",
    "\n",
    "def EmpiricalBayes(samples :np.ndarray,v0:int) -> np.ndarray:\n",
    "    \"\"\"Empirical Bayes estimate of covariance matrix using Inverse Wishart prior\n",
    "    samples: nxd matrix\n",
    "    v0: int\n",
    "    returns: dxd covariance matrix\n",
    "    \"\"\"\n",
    "    n,d = samples.shape\n",
    "    v_opt = minimize(lambda x: objective_function_voptimal(x,n,d), v0)\n",
    "    del_opt = v_opt.x[0]/n * samples.T@samples\n",
    "    #  InvWishart(νopt + n,∆opt + Σn) Calculate the posterior mean\n",
    "    posterior_mean = (del_opt + samples.T@samples ) / (v_opt.x[0] + n - d - 1)\n",
    "    return posterior_mean  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b9db2",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0439dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [0.95639504 0.5114831 ] \n",
      " \t\t[0.5114831  1.70687007] \t Error : 0.78170100869855 \n",
      "\n",
      "N100 estimate : [1.09090575 0.06765193] \n",
      " \t\t[0.06765193 1.42585811] \t Error : 0.5891148760120036 \n",
      "\n",
      "N1000 estimate : [ 1.00312518 -0.00914911] \n",
      " \t\t[-0.00914911  1.92430787] \t Error : 0.07685361366732414 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mle_n10 = mle_estimate(n10)\n",
    "mle_n100 = mle_estimate(n100)\n",
    "mle_n1000 = mle_estimate(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mle_n10[0]} \\n \\t\\t{mle_n10[1]} \\t\", f\"Error : {get_error(true_cov, mle_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mle_n100[0]} \\n \\t\\t{mle_n100[1]} \\t\", f\"Error : {get_error(true_cov, mle_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mle_n1000[0]} \\n \\t\\t{mle_n1000[1]} \\t\", f\"Error : {get_error(true_cov, mle_n1000)}\" , \"\\n\")  \n",
    "errors['MLE'] = [get_error(true_cov, mle_n10), get_error(true_cov, mle_n100), get_error(true_cov, mle_n1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4dcd0",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d74ed6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.1303292  0.42623591] \n",
      " \t\t[0.42623591 1.83905839] \t Error : 0.6373711732031411 \n",
      "\n",
      "N100 estimate : [1.10873113 0.06632542] \n",
      " \t\t[0.06632542 1.44691971] \t Error : 0.5714178737942226 \n",
      "\n",
      "N1000 estimate : [ 1.00511495 -0.00913085] \n",
      " \t\t[-0.00913085  1.92545696] \t Error : 0.07582593953464452 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta0 = np.array([[4,0],[0,5]])\n",
    "v0 = 5\n",
    "bayes_invwis_n10 = bayesian_estimate(n10, delta0, v0)\n",
    "bayes_invwis_n100 = bayesian_estimate(n100, delta0, v0)\n",
    "bayes_invwis_n1000 = bayesian_estimate(n1000, delta0, v0)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {bayes_invwis_n10[0]} \\n \\t\\t{bayes_invwis_n10[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {bayes_invwis_n100[0]} \\n \\t\\t{bayes_invwis_n100[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {bayes_invwis_n1000[0]} \\n \\t\\t{bayes_invwis_n1000[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n1000)}\" , \"\\n\")  \n",
    "errors['Bayes Inv Wishart'] = [get_error(true_cov, bayes_invwis_n10), get_error(true_cov, bayes_invwis_n100), get_error(true_cov, bayes_invwis_n1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb5020",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "41b85215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.1954938  0.63935387] \n",
      " \t\t[0.63935387 2.13358758] \t Error : 0.9346711809305068 \n",
      "\n",
      "N100 estimate : [1.11316913 0.06903258] \n",
      " \t\t[0.06903258 1.45495725] \t Error : 0.5651635564589236 \n",
      "\n",
      "N1000 estimate : [ 1.00513545 -0.00916745] \n",
      " \t\t[-0.00916745  1.9281642 ] \t Error : 0.07317676920946582 \n",
      "\n",
      "\n",
      "\n",
      "N10 estimate : [1.36627863 0.73069014] \n",
      " \t\t[0.73069014 2.43838581] \t Error : 1.180744813626069 \n",
      "\n",
      "N100 estimate : [1.1246451  0.06974426] \n",
      " \t\t[0.06974426 1.46995681] \t Error : 0.5533630885390415 \n",
      "\n",
      "N1000 estimate : [ 1.00614361 -0.00917664] \n",
      " \t\t[-0.00917664  1.93009816] \t Error : 0.07136127951600006 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta0 = np.array([[0,0],[0,0]])\n",
    "v0 = 1\n",
    "jeffery_n10 = bayesian_estimate(n10, delta0, v0)\n",
    "jeffery_n100 = bayesian_estimate(n100, delta0, v0)\n",
    "jeffery_n1000 = bayesian_estimate(n1000, delta0, v0)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {jeffery_n10[0]} \\n \\t\\t{jeffery_n10[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {jeffery_n100[0]} \\n \\t\\t{jeffery_n100[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {jeffery_n1000[0]} \\n \\t\\t{jeffery_n1000[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n1000)}\" , \"\\n\") \n",
    "print(\"\\n\")\n",
    "errors['Bayes Jeffery'] = [get_error(true_cov, jeffery_n10), get_error(true_cov, jeffery_n100), get_error(true_cov, jeffery_n1000)]\n",
    "\n",
    "v0 = 0\n",
    "jeffery_n10 = bayesian_estimate(n10, delta0, v0)\n",
    "jeffery_n100 = bayesian_estimate(n100, delta0, v0)\n",
    "jeffery_n1000 = bayesian_estimate(n1000, delta0, v0)\n",
    "\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {jeffery_ind_n10[0]} \\n \\t\\t{jeffery_ind_n10[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {jeffery_ind_n100[0]} \\n \\t\\t{jeffery_ind_n100[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {jeffery_ind_n1000[0]} \\n \\t\\t{jeffery_ind_n1000[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n1000)}\" , \"\\n\")  \n",
    "errors['Bayes Jeffery Ind'] = [get_error(true_cov, jeffery_ind_n10), get_error(true_cov, jeffery_ind_n100), get_error(true_cov, jeffery_ind_n1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e303b",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58794b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1498caabf9748aeb38384122ef555bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebb9ace310e411ca24bd119537c99d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1fe20972df438aa2700adac93dea23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cff485c074543dd8ccd780872acaf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [[1.14110165 0.43627623]\n",
      " [0.43627623 1.8258436 ]] \n",
      " \t\t[[1.12646981 0.42330231]\n",
      " [0.42330231 1.84736913]] \t Error : [0.6564404205471257, 0.6306032754799463, 0.6426690758770617] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be14bd2341954c45845c8ae38175cc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae868d1cc984ccaa98d6544cb9bd8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a1653c7fbf402e94066886f2c1f6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d2548e0f5f47dfa3ee177f62b2b8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccff3ac9b4d4bf39522445fc7e2b62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9c65ed57af4f07b2e141937c654420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1afd78c88a54a06a838bdbc0bda11cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67491852ca3a4961ae4d9d1a298dbc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [[1.14110165 0.43627623]\n",
      " [0.43627623 1.8258436 ]] \n",
      " \t\t[[1.12646981 0.42330231]\n",
      " [0.42330231 1.84736913]] \t Error : [0.6564404205471257, 0.6306032754799463, 0.6426690758770617] \n",
      "\n",
      "N100 estimate : [[1.1237665  0.04812369]\n",
      " [0.04812369 1.51117145]] \n",
      " \t\t[[1.12056661 0.05766659]\n",
      " [0.05766659 1.4516    ]] \t Error : [0.5088253855694996, 0.5673885282696627, 0.5655001658679221] \n",
      "\n",
      "N1000 estimate : [[1.04366923 0.04016991]\n",
      " [0.04016991 1.85321752]] \n",
      " \t\t[[1.02266425 0.01443503]\n",
      " [0.01443503 1.90017808]] \t Error : [0.16333812057173122, 0.10437827342499945, 0.07949564783002683] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebbb100fbe746b89e740d51e8ead8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8598cd2a7434c498e8ef55cedebf28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3921c29ae7f485c9da83c7337feac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd79916ab8c457e9df2a5eda82adca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e876f5807c09454cb6525ad58fe65fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24c417be9744e8c815715e4386c30bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d94cf737034edfbb4f681c0221c511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7f10024ea047ff91654a14377d7555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693296eab49b4c51a22f4c5f8b46529a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a150b71241764492a8d36688c37f35ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c165994c8ea4cafa03c22def9ab7827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70bf1cbf1f74ffd84776323c199c35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [[0.16371264 0.01864841]\n",
      " [0.01864841 0.31191436]] \n",
      " \t\t[[0.13352261 0.00280176]\n",
      " [0.00280176 0.31742649]] \t Error : [1.8840661373271026, 1.892578233570864, 1.8687357966899243] \n",
      "\n",
      "N100 estimate : [[0.14848515 0.02668915]\n",
      " [0.02668915 0.26057462]] \n",
      " \t\t[[ 0.16338485 -0.03012443]\n",
      " [-0.03012443  0.20083881]] \t Error : [1.9370345433066758, 1.9846210844515197, 2.004904615297301] \n",
      "\n",
      "N1000 estimate : [[0.46068712 0.01947195]\n",
      " [0.01947195 0.9643173 ]] \n",
      " \t\t[[0.4830285  0.00424663]\n",
      " [0.00424663 0.94960993]] \t Error : [1.1680134248446845, 1.1707326338567143, 1.171248389323076] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta0 = np.array([[4,0],[0,5]])\n",
    "v0 = 5\n",
    "mc_a_n10 = bayesian_estimate_using_MC(n10, delta0, v0)\n",
    "print(f\"N10 estimate : {mc_a_n10[0]} \\n \\t\\t{mc_a_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n10] }\" , \"\\n\")\n",
    "\n",
    "mc_a_n100 = bayesian_estimate_using_MC(n100, delta0, v0)\n",
    "mc_a_n1000 = bayesian_estimate_using_MC(n1000, delta0, v0)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mc_a_n10[0]} \\n \\t\\t{mc_a_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n10] }\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mc_a_n100[0]} \\n \\t\\t{mc_a_n100[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n100]}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mc_a_n1000[0]} \\n \\t\\t{mc_a_n1000[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n1000]}\" , \"\\n\") \n",
    "print(\"\\n\")\n",
    "errors['MC Bayes with prior 1'] = [get_error(true_cov, mc_a_n10[-1]), get_error(true_cov, mc_a_n100[-1]), get_error(true_cov, mc_a_n1000[-1])]\n",
    "\n",
    "delta0 = np.array([[2,0],[0,4]])\n",
    "mc_a_n10 = bayesian_estimate_using_MC(n10, delta0, v0)\n",
    "mc_a_n100 = bayesian_estimate_using_MC(n100, delta0, v0)\n",
    "mc_a_n1000 = bayesian_estimate_using_MC(n1000, delta0, v0)\n",
    "errors['MC Bayes with prior 1'] = [get_error(true_cov, mc_a_n10[-1]), get_error(true_cov, mc_a_n100[-1]), get_error(true_cov, mc_a_n1000[-1])]\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mc_b_n10[0]} \\n \\t\\t{mc_b_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n10]}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mc_b_n100[0]} \\n \\t\\t{mc_b_n100[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n100]}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mc_b_n1000[0]} \\n \\t\\t{mc_b_n1000[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n1000]}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753fad5",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8981f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bcadf99ee74346b8b1acab7156f49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058d6f4c1d484c5bb01066afa19f4364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5d86b4f54d4a3fb9dff14dddb16cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [0.75748028 0.39584174] \n",
      " \t\t[0.39584174 1.33822396] \t Error : 0.9000803915592668 \n",
      "\n",
      "N100 estimate : [1.07205669 0.06179633] \n",
      " \t\t[0.06179633 1.39347467] \t Error : 0.6170111164981116 \n",
      "\n",
      "N1000 estimate : [ 1.00992556 -0.00929338] \n",
      " \t\t[-0.00929338  1.92875955] \t Error : 0.07311943875823071 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sigma0 = np.array([[4,0],[0,5]])\n",
    "v0 = 5\n",
    "gibbs_n10 = gibbs_sampler(n10, sigma0, v0)\n",
    "gibbs_n100 = gibbs_sampler(n100, sigma0, v0)\n",
    "gibbs_n1000 = gibbs_sampler(n1000, sigma0, v0)\n",
    "errors['Gibbs'] = [get_error(true_cov, gibbs_n10), get_error(true_cov, gibbs_n100), get_error(true_cov, gibbs_n1000)]\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {gibbs_n10[0]} \\n \\t\\t{gibbs_n10[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {gibbs_n100[0]} \\n \\t\\t{gibbs_n100[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {gibbs_n1000[0]} \\n \\t\\t{gibbs_n1000[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n1000)}\" , \"\\n\") \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107aec9",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cba81e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.04157568 0.55703797] \n",
      " \t\t[0.55703797 1.85889121] \t Error : 0.8013880606137168 \n",
      "\n",
      "N100 estimate : [1.1246625  0.06974534] \n",
      " \t\t[0.06974534 1.46997955] \t Error : 0.5533454958740844 \n",
      "\n",
      "N1000 estimate : [ 1.00614376 -0.00917664] \n",
      " \t\t[-0.00917664  1.93009845] \t Error : 0.07136100844284828 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v0 = 5\n",
    "empirical_bayes_n10 = EmpiricalBayes(n10, v0)\n",
    "empirical_bayes_n100 = EmpiricalBayes(n100, v0)\n",
    "empirical_bayes_n1000 = EmpiricalBayes(n1000, v0)\n",
    "errors['Empirical Bayes'] = [get_error(true_cov, empirical_bayes_n10), get_error(true_cov, empirical_bayes_n100), get_error(true_cov, empirical_bayes_n1000)]\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {empirical_bayes_n10[0]} \\n \\t\\t{empirical_bayes_n10[1]} \\t\", f\"Error : {get_error(true_cov, empirical_bayes_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {empirical_bayes_n100[0]} \\n \\t\\t{empirical_bayes_n100[1]} \\t\", f\"Error : {get_error(true_cov, empirical_bayes_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {empirical_bayes_n1000[0]} \\n \\t\\t{empirical_bayes_n1000[1]} \\t\", f\"Error : {get_error(true_cov, empirical_bayes_n1000)}\" , \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
