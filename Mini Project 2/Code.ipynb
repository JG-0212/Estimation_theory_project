{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b263fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import invwishart, invgamma\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import gamma \n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249225d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "def generate_samples(n):\n",
    "    # size = nx2\n",
    "    mean = np.array([0,0])\n",
    "    cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "    samples = np.random.multivariate_normal(mean,cov,size=n)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba6412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n10 = generate_samples(10)\n",
    "n100 = generate_samples(100)\n",
    "n1000 = generate_samples(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "590fb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(samples, estimate):\n",
    "    return np.linalg.norm(samples - estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d75da",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8104fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gammafn(x,d):\n",
    "    init = np.pi**(d*(d-1)/4)\n",
    "    for i in range(1,d+1):\n",
    "        init *= gamma(x + (1-i)/2)\n",
    "    return init\n",
    "def objective_function_voptimal(v,n,d):\n",
    "    term_1 = v*np.log((v+n)/v)\n",
    "    term_2 = n*np.log((v+n)/n)\n",
    "    term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
    "    return term_1 + term_2 + term_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b191fe",
   "metadata": {},
   "source": [
    "## Ques - 1 : MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc131dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_estimate(samples):\n",
    "    return samples.T@samples/len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a23bf0dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m mle_n1000 \u001b[38;5;241m=\u001b[39m mle_estimate(n1000)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(f\"  Estimate  \\t|\\t Error \\n\")\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN10 estimate : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmle_n10[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmle_n10[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mget_error\u001b[49m(true_cov,\u001b[38;5;250m \u001b[39mmle_n10)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN100 estimate : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmle_n100[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmle_n100[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_error(true_cov,\u001b[38;5;250m \u001b[39mmle_n100)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN1000 estimate : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmle_n1000[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmle_n1000[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_error(true_cov,\u001b[38;5;250m \u001b[39mmle_n1000)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_error' is not defined"
     ]
    }
   ],
   "source": [
    "mle_n10 = mle_estimate(n10)\n",
    "mle_n100 = mle_estimate(n100)\n",
    "mle_n1000 = mle_estimate(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mle_n10[0]} \\n \\t\\t{mle_n10[1]} \\t\", f\"Error : {get_error(true_cov, mle_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mle_n100[0]} \\n \\t\\t{mle_n100[1]} \\t\", f\"Error : {get_error(true_cov, mle_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mle_n1000[0]} \\n \\t\\t{mle_n1000[1]} \\t\", f\"Error : {get_error(true_cov, mle_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac089be",
   "metadata": {},
   "source": [
    "### Ques - 2 : Bayesian Est with Conjugate Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_invwishart_cp(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    d = 1\n",
    "    dof = n + v0\n",
    "    scale = delta0 + samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.0433808  0.39344854] \n",
      " \t\t[0.39344854 1.69759236] \t Error : 0.6347722240374717 \n",
      "\n",
      "N100 estimate : [1.09796675 0.06568148] \n",
      " \t\t[0.06568148 1.43287195] \t Error : 0.5829749793964033 \n",
      "\n",
      "N1000 estimate : [ 1.00411284 -0.00912175] \n",
      " \t\t[-0.00912175  1.92353726] \t Error : 0.07765229561546955 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bayes_invwis_n10 = bayesian_estimate_invwishart_cp(n10)\n",
    "bayes_invwis_n100 = bayesian_estimate_invwishart_cp(n100)\n",
    "bayes_invwis_n1000 = bayesian_estimate_invwishart_cp(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {bayes_invwis_n10[0]} \\n \\t\\t{bayes_invwis_n10[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {bayes_invwis_n100[0]} \\n \\t\\t{bayes_invwis_n100[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {bayes_invwis_n1000[0]} \\n \\t\\t{bayes_invwis_n1000[1]} \\t\", f\"Error : {get_error(true_cov, bayes_invwis_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a3171",
   "metadata": {},
   "source": [
    "### Ques - 3 : Bayesian Est with Non-informative Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ebc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_jeffery(samples):\n",
    "    # https://tminka.github.io/papers/minka-gaussian.pdf\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)\n",
    "\n",
    "def bayesian_estimate_ind_jeffery(samples):\n",
    "    # gelman page 72\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n - 1\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [1.1954938  0.63935387] \n",
      " \t\t[0.63935387 2.13358758] \t Error : 0.9346711809305068 \n",
      "\n",
      "N100 estimate : [1.11316913 0.06903258] \n",
      " \t\t[0.06903258 1.45495725] \t Error : 0.5651635564589236 \n",
      "\n",
      "N1000 estimate : [ 1.00513545 -0.00916745] \n",
      " \t\t[-0.00916745  1.9281642 ] \t Error : 0.07317676920946625 \n",
      "\n",
      "\n",
      "\n",
      "N10 estimate : [1.36627863 0.73069014] \n",
      " \t\t[0.73069014 2.43838581] \t Error : 1.1807448136260692 \n",
      "\n",
      "N100 estimate : [1.1246451  0.06974426] \n",
      " \t\t[0.06974426 1.46995681] \t Error : 0.5533630885390415 \n",
      "\n",
      "N1000 estimate : [ 1.00614361 -0.00917664] \n",
      " \t\t[-0.00917664  1.93009816] \t Error : 0.0713612795160005 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jeffery_n10 = bayesian_estimate_jeffery(n10)\n",
    "jeffery_n100 = bayesian_estimate_jeffery(n100)\n",
    "jeffery_n1000 = bayesian_estimate_jeffery(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {jeffery_n10[0]} \\n \\t\\t{jeffery_n10[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {jeffery_n100[0]} \\n \\t\\t{jeffery_n100[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {jeffery_n1000[0]} \\n \\t\\t{jeffery_n1000[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_n1000)}\" , \"\\n\") \n",
    "print(\"\\n\")\n",
    "\n",
    "jeffery_ind_n10 = bayesian_estimate_ind_jeffery(n10)\n",
    "jeffery_ind_n100 = bayesian_estimate_ind_jeffery(n100)\n",
    "jeffery_ind_n1000 = bayesian_estimate_ind_jeffery(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {jeffery_ind_n10[0]} \\n \\t\\t{jeffery_ind_n10[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {jeffery_ind_n100[0]} \\n \\t\\t{jeffery_ind_n100[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {jeffery_ind_n1000[0]} \\n \\t\\t{jeffery_ind_n1000[1]} \\t\", f\"Error : {get_error(true_cov, jeffery_ind_n1000)}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacb7f7",
   "metadata": {},
   "source": [
    "### Ques 4 : MC Bayesian Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_bayesian_a(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    vals = []\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "\n",
    "\n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            det_term = np.clip(det_term, 1e-100, 1e100)\n",
    "\n",
    "            exp_term = np.exp(np.clip(-0.5*np.trace(np.linalg.inv(sigma_j)@(samples.T@samples)), -100, 100))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\")\n",
    "        vals.append(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    return np.array(vals)\n",
    "\n",
    "def mc_bayesian_b(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[2,0],[0,4]])\n",
    "    vals = []\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            \n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            det_term = np.clip(det_term, 1e-100, 1e100)\n",
    "\n",
    "            exp_term = np.exp(np.clip(-0.5*np.trace(np.linalg.inv(sigma_j)@(samples.T@samples)), -100, 100))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\")\n",
    "        vals.append(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    return np.array(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821976f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=1000.0:\n",
      "[[1.14750261 0.41344169]\n",
      " [0.41344169 1.76454058]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[1.13729556 0.43422316]\n",
      " [0.43422316 1.84828843]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[1.12964945 0.42687344]\n",
      " [0.42687344 1.83704482]]\n",
      "\n",
      "\n",
      "For m=1000.0:\n",
      "[[ 0.31320765 -0.05271226]\n",
      " [-0.05271226  0.31963124]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[ 0.28152285 -0.03961383]\n",
      " [-0.03961383  0.26570593]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[ 0.21161226 -0.06975444]\n",
      " [-0.06975444  0.27004901]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcdpm\\AppData\\Local\\Temp\\ipykernel_20396\\2857128785.py:19: RuntimeWarning: overflow encountered in scalar power\n",
      "  det_term = np.linalg.det(sigma_j)**(-n/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=1000.0:\n",
      "[[0.64683946 0.02515833]\n",
      " [0.02515833 0.82488662]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[0.65887673 0.00255673]\n",
      " [0.00255673 0.82126412]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[ 6.59941724e-01 -8.11756238e-04]\n",
      " [-8.11756238e-04  8.25364219e-01]]\n",
      "\n",
      "\n",
      "N10 estimate : [[1.14750261 0.41344169]\n",
      " [0.41344169 1.76454058]] \n",
      " \t\t[[1.13729556 0.43422316]\n",
      " [0.43422316 1.84828843]] \t Error : [0.6473532371247749, 0.6472758192414859, 0.6385963029495249] \n",
      "\n",
      "N100 estimate : [[ 0.31320765 -0.05271226]\n",
      " [-0.05271226  0.31963124]] \n",
      " \t\t[[ 0.28152285 -0.03961383]\n",
      " [-0.03961383  0.26570593]] \t Error : [1.8168324312854691, 1.8780638531030667, 1.9036851112569915] \n",
      "\n",
      "N1000 estimate : [[0.64683946 0.02515833]\n",
      " [0.02515833 0.82488662]] \n",
      " \t\t[[0.65887673 0.00255673]\n",
      " [0.00255673 0.82126412]] \t Error : [1.227550285214802, 1.2271089734121554, 1.2228696443345275] \n",
      "\n",
      "\n",
      "\n",
      "For m=1000.0:\n",
      "[[0.97055226 0.44532681]\n",
      " [0.44532681 1.78088291]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[0.97500692 0.43525919]\n",
      " [0.43525919 1.76810838]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[0.96971216 0.43069749]\n",
      " [0.43069749 1.75689593]]\n",
      "\n",
      "\n",
      "For m=1000.0:\n",
      "[[ 0.20484956 -0.00955182]\n",
      " [-0.00955182  0.29402739]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[0.09728612 0.04216625]\n",
      " [0.04216625 0.26260529]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[0.10061765 0.02423758]\n",
      " [0.02423758 0.26764923]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcdpm\\AppData\\Local\\Temp\\ipykernel_20396\\2857128785.py:45: RuntimeWarning: overflow encountered in scalar power\n",
      "  det_term = np.linalg.det(sigma_j)**(-n/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m=1000.0:\n",
      "[[0.46848878 0.00661777]\n",
      " [0.00661777 0.98335474]]\n",
      "\n",
      "\n",
      "For m=10000.0:\n",
      "[[ 0.47172908 -0.00914788]\n",
      " [-0.00914788  0.95894768]]\n",
      "\n",
      "\n",
      "For m=100000.0:\n",
      "[[ 0.47680919 -0.00103238]\n",
      " [-0.00103238  0.95771684]]\n",
      "\n",
      "\n",
      "N10 estimate : [[0.97055226 0.44532681]\n",
      " [0.44532681 1.78088291]] \n",
      " \t\t[[0.97500692 0.43525919]\n",
      " [0.43525919 1.76810838]] \t Error : [0.6674664118655235, 0.6582548852753701, 0.6565192995883354] \n",
      "\n",
      "N100 estimate : [[ 0.20484956 -0.00955182]\n",
      " [-0.00955182  0.29402739]] \n",
      " \t\t[[0.09728612 0.04216625]\n",
      " [0.04216625 0.26260529]] \t Error : [1.882229855168189, 1.9588233016940195, 1.9522045779222439] \n",
      "\n",
      "N1000 estimate : [[0.46848878 0.00661777]\n",
      " [0.00661777 0.98335474]] \n",
      " \t\t[[ 0.47172908 -0.00914788]\n",
      " [-0.00914788  0.95894768]] \t Error : [1.1472398805591821, 1.167487675616894, 1.1662267964403852] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_a_n10 = mc_bayesian_a(n10)\n",
    "mc_a_n100 = mc_bayesian_a(n100)\n",
    "mc_a_n1000 = mc_bayesian_a(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mc_a_n10[0]} \\n \\t\\t{mc_a_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n10] }\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mc_a_n100[0]} \\n \\t\\t{mc_a_n100[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n100]}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mc_a_n1000[0]} \\n \\t\\t{mc_a_n1000[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_a_n1000]}\" , \"\\n\") \n",
    "print(\"\\n\")\n",
    "\n",
    "mc_b_n10 =  mc_bayesian_b(n10)\n",
    "mc_b_n100 =  mc_bayesian_b(n100)\n",
    "mc_b_n1000 =  mc_bayesian_b(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {mc_b_n10[0]} \\n \\t\\t{mc_b_n10[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n10]}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {mc_b_n100[0]} \\n \\t\\t{mc_b_n100[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n100]}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {mc_b_n1000[0]} \\n \\t\\t{mc_b_n1000[1]} \\t\", f\"Error : {[get_error(true_cov, x) for x in mc_b_n1000]}\" , \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901bb1c",
   "metadata": {},
   "source": [
    "### Ques - 5 : Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler(samples):\n",
    "    n = len(samples)\n",
    "    d = 2\n",
    "    v = 5 # to be checked\n",
    "    iter = 1e5\n",
    "    A_1 = 0.05\n",
    "    A_2 = 0.05\n",
    "\n",
    "    a1 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    a2 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    \n",
    "    sigmas = []\n",
    "    for i in tqdm(range(int(iter))):\n",
    "        if i%2 == 0:\n",
    "            sigma = invwishart.rvs(v+d+n-1, 2*v*np.array([[1/a1,0],[0,1/a2]])+samples.T@samples)\n",
    "            sigmas.append(sigma)\n",
    "        else:\n",
    "            a1 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[0][0])+1/(A_1**2))\n",
    "            a2 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[1][1])+1/(A_2**2))\n",
    "    \n",
    "    return np.array(sigmas[-1000:]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7026a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b141449e161a4ed288b41a4f6551e5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9308749f16b542f6b65b12b98d777c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae51195492ab4a8bbf99885152a50611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N10 estimate : [0.74187307 0.3909514 ] \n",
      " \t\t[0.3909514  1.34889428] \t Error : 0.89233074886173 \n",
      "\n",
      "N100 estimate : [1.06740812 0.06234312] \n",
      " \t\t[0.06234312 1.40153267] \t Error : 0.608670949224485 \n",
      "\n",
      "N1000 estimate : [ 1.01154891 -0.01157512] \n",
      " \t\t[-0.01157512  1.93106917] \t Error : 0.07178303140038926 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gibbs_n10 = gibbs_sampler(n10)\n",
    "gibbs_n100 = gibbs_sampler(n100)\n",
    "gibbs_n1000 = gibbs_sampler(n1000)\n",
    "\n",
    "# print(f\"  Estimate  \\t|\\t Error \\n\")\n",
    "print(f\"N10 estimate : {gibbs_n10[0]} \\n \\t\\t{gibbs_n10[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n10)}\" , \"\\n\")\n",
    "print(f\"N100 estimate : {gibbs_n100[0]} \\n \\t\\t{gibbs_n100[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n100)}\", \"\\n\")\n",
    "print(f\"N1000 estimate : {gibbs_n1000[0]} \\n \\t\\t{gibbs_n1000[1]} \\t\", f\"Error : {get_error(true_cov, gibbs_n1000)}\" , \"\\n\") \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da30436",
   "metadata": {},
   "source": [
    "### Ques 6 : Empirical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97bf1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmpiricalBayes(samples,v0):\n",
    "    n,d = samples.shape\n",
    "    v_opt = minimize(lambda x: objective_function_voptimal(x,n,d), v0)\n",
    "    del_opt = v_opt.x[0]/n * samples.T@samples \n",
    "    #  InvWishart(νopt + n,∆opt + Σn) Calculate the posterior mean\n",
    "    posterior_mean = (del_opt + samples.T@samples ) / (v_opt.x[0] + n - d - 1)\n",
    "    return posterior_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a64349f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n = 10 \n",
      "[[0.63347098 0.19132897]\n",
      " [0.19132897 1.32014929]]\n",
      "For n = 10 \n",
      "[[ 1.12432537 -0.00780099]\n",
      " [-0.00780099  2.3160673 ]]\n",
      "For n = 10 \n",
      "[[1.04545965 0.01202806]\n",
      " [0.01202806 2.01267675]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:4: RuntimeWarning: overflow encountered in multiply\n",
      "  init *= gamma(x + (1-i)/2)\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:4: RuntimeWarning: overflow encountered in multiply\n",
      "  init *= gamma(x + (1-i)/2)\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:4: RuntimeWarning: overflow encountered in multiply\n",
      "  init *= gamma(x + (1-i)/2)\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
      "c:\\Users\\aksha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:596: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:4: RuntimeWarning: overflow encountered in multiply\n",
      "  init *= gamma(x + (1-i)/2)\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
      "c:\\Users\\aksha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:596: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n",
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_22688\\50817309.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  term_3 = np.log(gammafn(v/2,d)/gammafn((v+n)/2,d))\n",
      "c:\\Users\\aksha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:596: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n"
     ]
    }
   ],
   "source": [
    "print(f\"For n = 10 \\n{EmpiricalBayes(n10,5)}\")\n",
    "print(f\"For n = 10 \\n{EmpiricalBayes(n100,5)}\")\n",
    "print(f\"For n = 10 \\n{EmpiricalBayes(n1000,5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e2e4a",
   "metadata": {},
   "source": [
    "## Code without outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53299a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70647522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n):\n",
    "    # size = nx2\n",
    "    mean = np.array([0,0])\n",
    "    cov = np.array([[1,0],[0,2]])\n",
    "\n",
    "    samples = np.random.multivariate_normal(mean,cov,size=n)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae8cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n10 = generate_samples(10)\n",
    "n100 = generate_samples(100)\n",
    "n1000 = generate_samples(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbaaf67",
   "metadata": {},
   "source": [
    "### Ques - 1 : MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cceacf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_estimate(samples):\n",
    "    return samples.T@samples/len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed3658",
   "metadata": {},
   "source": [
    "### Ques - 2 : Bayesian Est with Conjugate Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecde9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_invwishart_cp(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "    d = 1\n",
    "    dof = n + v0\n",
    "    scale = delta0 + samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5e61a",
   "metadata": {},
   "source": [
    "### Ques - 3 : Bayesian Est with Non-informative Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e92853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_estimate_jeffery(samples):\n",
    "    # https://tminka.github.io/papers/minka-gaussian.pdf\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)\n",
    "\n",
    "def bayesian_estimate_ind_jeffery(samples):\n",
    "    # gelman page 72\n",
    "    n = len(samples)\n",
    "    d = 1\n",
    "    dof = n - 1\n",
    "    scale = samples.T@samples\n",
    "    \n",
    "    # return analytical mean of posterior\n",
    "    return scale/(dof-d-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d3087",
   "metadata": {},
   "source": [
    "### Ques 4 : MC Bayesian Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f869ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_bayesian_a(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[4,0],[0,5]])\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            exp_term = np.exp(-0.5*np.linalg.trace(np.linalg.inv(sigma_j)@(samples.T@samples)))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\\n\")\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n",
    "\n",
    "def mc_bayesian_b(samples):\n",
    "    n = len(samples)\n",
    "    v0 = 5\n",
    "    delta0 = np.array([[2,0],[0,4]])\n",
    "\n",
    "    for m in [1e3, 1e4, 1e5]:\n",
    "        numerators = []\n",
    "        denominators = []\n",
    "        for _ in range(int(m)):\n",
    "            sigma_j = invwishart.rvs(v0,delta0)\n",
    "            det_term = np.linalg.det(sigma_j)**(-n/2)\n",
    "            exp_term = np.exp(-0.5*np.linalg.trace(np.linalg.inv(sigma_j)@(samples.T@samples)))\n",
    "            numerators.append(sigma_j*det_term*exp_term)\n",
    "            denominators.append(det_term*exp_term)\n",
    "\n",
    "        print(f\"For m={m}:\\n\")\n",
    "        print(np.array(numerators).mean(axis=0)/np.mean(denominators))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd4c50",
   "metadata": {},
   "source": [
    "### Ques - 5 : Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a77ed715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler(samples):\n",
    "    n = len(samples)\n",
    "    d = 2\n",
    "    v = 5 # to be checked\n",
    "    iter = 1e3\n",
    "    A_1 = 0.05\n",
    "    A_2 = 0.05\n",
    "\n",
    "    a1 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    a2 = invgamma.rvs(0.5, scale = 1/(A_1**2))\n",
    "    \n",
    "    sigmas = []\n",
    "    for i in range(int(iter)):\n",
    "        if i%2 == 0:\n",
    "            sigma = invwishart.rvs(v+d+n-1, 2*v*np.array([[1/a1,0],[0,1/a2]])+samples.T@samples)\n",
    "            sigmas.append(sigma)\n",
    "        else:\n",
    "            a1 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[0][0])+1/(A_1**2))\n",
    "            a2 = invgamma.rvs((v+n)/2,scale=v*(np.linalg.inv(sigma)[1][1])+1/(A_2**2))\n",
    "    \n",
    "    return np.array(sigmas).mean(axis=0)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170bb91",
   "metadata": {},
   "source": [
    "### Ques 6 : Empirical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae920d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "est_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
